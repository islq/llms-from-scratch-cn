{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
   "metadata": {
    "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
   },
   "source": [
    "# 第6章：用于文本分类的微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "9495f150-9d79-4910-d6e7-6c0d9aae4a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.0\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.3.1\n",
      "pandas version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        # \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
   "metadata": {
    "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
   },
   "source": [
    "## 6.1 不同类别的微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
   "metadata": {
    "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
   },
   "source": [
    "- 本节没有代码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
   "metadata": {},
   "source": [
    "- 微调语言模型最常见的方法是指令微调和分类微调\n",
    "- 如下所示的指令微调是下一章的主题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/instructions.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
   "metadata": {},
   "source": [
    "- 本章的主题是分类微调，如果您有机器学习背景，您可能已经熟悉这个过程 -- 例如，它类似于训练卷积网络来对手写数字进行分类\n",
    "- 在分类微调中，我们有模型可以输出的特定数量的类标签，例如“垃圾邮件”和“非垃圾邮件”\n",
    "- 分类微调模型只能预测在训练期间看到的类别，例如“垃圾邮件”或“非垃圾邮件”，而指令微调模型通常可以执行许多任务\n",
    "- 我们可以将分类微调模型视为非常专业的模型； 在实践中，创建专门的模型比创建在许多不同任务上表现良好的通用模型要容易得多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/spam-non-spam.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## 6.2 准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-1.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
   "metadata": {
    "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
   },
   "source": [
    "- 本节准备我们用于分类微调的数据集\n",
    "- 我们使用包含垃圾邮件和非垃圾邮件文本序列消息的数据集来微调 LLM 以对它们进行分类\n",
    "- 首先，我们下载并解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "424e4423-f623-443c-ab9e-656f9e867559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # 下载文件\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # 解压文件\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # 添加 .tsv 文件扩展\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
   "metadata": {
    "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
   },
   "source": [
    "- 数据集保存为制表符分隔的文本序列文件，我们可以将其加载到 pandas DataFrame 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
    "outputId": "a16c5cde-d341-4887-a93f-baa9bec542ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
   "metadata": {
    "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
   },
   "source": [
    "- 当我们检查类别分布时，我们发现数据中包含“ham”（即“非垃圾邮件”）的频率比“垃圾邮件”的频率高得多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
    "outputId": "761e0482-43ba-4f46-f4b7-6774dae51b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
   "metadata": {
    "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
   },
   "source": [
    "- 为简单起见，并且因为无论如何我们更喜欢用于教育目的的小数据集（这将使 LLM 更快地微调成为可能），我们对数据集进行了二次采样（欠采样），以便它包含每个类别的 747 个实例\n",
    "- 除了欠采样之外，还有其他几种处理类平衡的方法，但它们超出了一本大模型书籍的范围；您可以在 [`imbalanced-learn` 用户指南](https://imbalanced-learn.org/stable/user_guide.html)中找到示例和更多信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be4a0a2-9704-4a96-b38f-240339818688",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7be4a0a2-9704-4a96-b38f-240339818688",
    "outputId": "396dc415-cb71-4a88-e85d-d88201c6d73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # 计算\"spam\"实例的数量\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # 随机采样\"ham\"实例以匹配\"spam\"实例的数量\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # 将\"ham\"子集与\"spam\"结合起来\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
   "metadata": {
    "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
   },
   "source": [
    "- 接下来，我们将字符串类标签\"ham\"和\"spam\"更改为整数类标签0和1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
   "metadata": {
    "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
   },
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
   "metadata": {
    "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
   },
   "source": [
    "- 现在让我们定义一个函数，将数据集随机划分为训练、验证和测试子集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uQl0Psdmx15D",
   "metadata": {
    "id": "uQl0Psdmx15D"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # 打乱整个 DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # 计算切分索引\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # 切分 DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# 测试大小默认为 0.2\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
   "metadata": {},
   "source": [
    "## 6.3 创建数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
   "metadata": {
    "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
   },
   "source": [
    "- 请注意文本序列有不同的长度； 如果我们想在一批中组合多个训练示例，我们必须\n",
    "   1. 将所有消息截断为数据集或批次中最短文本序列的长度\n",
    "   2. 将所有消息填充到数据集或批次中最长文本序列的长度\n",
    "\n",
    "- 我们选择选项 2，并将所有文本序列填充到数据集中最长的文本序列\n",
    "- 为此，我们使用 `<|endoftext|>` 作为填充标记，如第 2 章所述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829f33f-1428-4f22-9886-7fee633b3666",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/pad-input-sequences.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
    "outputId": "b5b48439-32c8-4b37-cca2-c9dc8fa86563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
   "metadata": {
    "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
   },
   "source": [
    "- 下面的`SpamDataset`类标识训练数据集中最长的序列，并将填充标记添加到其他序列中以匹配该序列长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
   "metadata": {
    "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # 预标记文本\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # 如果序列长于 max_length，则截断序列\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # 将序列填充到最长序列\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uzj85f8ou82h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj85f8ou82h",
    "outputId": "d08f1cf0-c24d-445f-a3f8-793532c3716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
   "metadata": {},
   "source": [
    "- 我们还将验证和测试集填充到最长的训练序列\n",
    "- 请注意，比最长训练示例更长的验证和测试集样本将通过`SpamDataset`代码中的`encoded_text[:self.max_length]`被截断\n",
    "- 此行为完全是可选的，如果我们在验证集和测试集案例中设置`max_length=None`，它也会很好地工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
   "metadata": {
    "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
   },
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170d89-85a0-4844-9887-832f5d23432a",
   "metadata": {},
   "source": [
    "- 接下来，我们使用数据集来实例化数据加载器，这与前面章节中创建数据加载器类似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/batch.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
    "outputId": "3266c410-4fdb-4a8c-a142-7f707e2525ab"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {},
   "source": [
    "- 作为验证步骤，我们迭代数据加载器并确保每个批次包含 8 个训练示例，其中每个训练示例包含 120 个标记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {},
   "source": [
    "- 最后，让我们打印每个数据集中的批次总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "6934bbf2-9797-4fbe-d26b-1a246e18c2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
   "metadata": {
    "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
   },
   "source": [
    "## 6.4 使用预训练权重初始化模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
   "metadata": {},
   "source": [
    "- 在本节中，我们初始化上一章中使用的预训练模型\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-2.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
   "metadata": {
    "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "518b1d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "\n",
    "# allowed model names\n",
    "model_names = {\n",
    "    \"gpt2-small\": \"openai-community/gpt2\",         # 124M\n",
    "    \"gpt2-medium\": \"openai-community/gpt2-medium\", # 355M\n",
    "    \"gpt2-large\": \"openai-community/gpt2-large\",   # 774M\n",
    "    \"gpt2-xl\": \"openai-community/gpt2-xl\"          # 1558M\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small\"\n",
    "\n",
    "gpt_hf = GPT2Model.from_pretrained(model_names[CHOOSE_MODEL], cache_dir=\"../../checkpoints\")\n",
    "gpt_hf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39e9c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign_check(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    # return torch.nn.Parameter(torch.tensor(right))\n",
    "    return torch.nn.Parameter(right.clone().detach())\n",
    "\n",
    "def load_weights(gpt, gpt_hf):\n",
    "\n",
    "    d = gpt_hf.state_dict()\n",
    "\n",
    "    gpt.pos_emb.weight = assign_check(gpt.pos_emb.weight, d[\"wpe.weight\"])\n",
    "    gpt.tok_emb.weight = assign_check(gpt.tok_emb.weight, d[\"wte.weight\"])\n",
    "    \n",
    "    for b in range(BASE_CONFIG[\"n_layers\"]):\n",
    "        q_w, k_w, v_w = np.split(d[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign_check(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign_check(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign_check(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split(d[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign_check(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign_check(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign_check(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "    \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign_check(gpt.trf_blocks[b].att.out_proj.weight, d[f\"h.{b}.attn.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign_check(gpt.trf_blocks[b].att.out_proj.bias, d[f\"h.{b}.attn.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign_check(gpt.trf_blocks[b].ff.layers[0].weight, d[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign_check(gpt.trf_blocks[b].ff.layers[0].bias, d[f\"h.{b}.mlp.c_fc.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign_check(gpt.trf_blocks[b].ff.layers[2].weight, d[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign_check(gpt.trf_blocks[b].ff.layers[2].bias, d[f\"h.{b}.mlp.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].norm1.scale = assign_check(gpt.trf_blocks[b].norm1.scale, d[f\"h.{b}.ln_1.weight\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign_check(gpt.trf_blocks[b].norm1.shift, d[f\"h.{b}.ln_1.bias\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign_check(gpt.trf_blocks[b].norm2.scale, d[f\"h.{b}.ln_2.weight\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign_check(gpt.trf_blocks[b].norm2.shift, d[f\"h.{b}.ln_2.bias\"])\n",
    "    \n",
    "        gpt.final_norm.scale = assign_check(gpt.final_norm.scale, d[f\"ln_f.weight\"])\n",
    "        gpt.final_norm.shift = assign_check(gpt.final_norm.shift, d[f\"ln_f.bias\"])\n",
    "        gpt.out_head.weight = assign_check(gpt.out_head.weight, d[\"wte.weight\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "097d3d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(model, gpt_hf)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e056c-abe0-415f-b34d-df686204259e",
   "metadata": {},
   "source": [
    "- 为了确保模型加载正确，让我们仔细检查它是否生成连贯的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69162550-6a02-4ece-8db1-06c71d61946f",
   "metadata": {},
   "source": [
    "- 在我们将模型微调为分类器之前，让我们看看模型是否已经可以通过提示对垃圾邮件进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' Answer with 'yes' or 'no'. Answer with 'yes' or 'no'. Answer with 'yes' or 'no'. Answer with 'yes'\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    "    \" Answer with 'yes' or 'no'.\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
   "metadata": {},
   "source": [
    "- 正如我们所看到的，该模型不太擅长遵循指令\n",
    "- 这是预料之中的，因为它只经过了预训练，没有进行指令微调（指令微调将在下一章中介绍）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
   "metadata": {
    "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
   },
   "source": [
    "## 6.5 添加分类头"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/lm-head.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217bac05-78df-4412-bd80-612f8061c01d",
   "metadata": {},
   "source": [
    "- 在本节中，我们正在修改预训练的 LLM，使其为分类微调做好准备\n",
    "- 我们先看一下模型架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d8f7a01-b7c0-48d4-b1e7-8c12cc7ad932",
    "outputId": "b6a5b9b5-a92f-498f-d7cb-b58dd99e4497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
   "metadata": {},
   "source": [
    "- 综上所述，我们可以看到我们在第 4 章中实现的模型架构\n",
    "- 我们的目标是替换和微调输出层\n",
    "- 为了实现这一目标，我们首先冻结模型，这意味着我们使所有层都不可训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fkMWFl-0etea",
   "metadata": {
    "id": "fkMWFl-0etea"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155f83-87d9-476a-a978-a15aa2d44147",
   "metadata": {},
   "source": [
    "- 然后，我们替换输出层（`model.out_head`），该层最初将层输入映射到 50,257 维（词汇表的大小）\n",
    "- 由于我们对二元分类模型进行了微调（预测 2 个类别，\"spam\" 和 \"not spam\"），因此我们可以如下所示替换输出层，默认情况下该输出层是可训练的\n",
    "- 请注意，我们使用 `BASE_CONFIG[\"emb_dim\"]` （在 `\"gpt2-small (124M)\"` 模型中等于 768）以使下面的代码更通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
   "metadata": {},
   "source": [
    "- 从技术上讲，仅训练输出层就足够了\n",
    "- 然而，正如我在[实验微调附加层](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)中发现可以显着提高性能\n",
    "- 因此，我们还使最后一个transformer块和将最后一个transformer块连接到输出层的最终`LayerNorm`模块可训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/trainable.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
   "metadata": {
    "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
   },
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
   "metadata": {},
   "source": [
    "- 我们仍然可以像之前的章节一样使用这个模型\n",
    "- 例如，让我们为其提供一些文本输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
    "outputId": "27e041b1-d731-48a1-cf60-f22d4565304e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
   "metadata": {},
   "source": [
    "- 与前几章不同的是，它现在有两个输出维度，而不是 50,257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
    "outputId": "9cae7448-253d-4776-973e-0af190b06354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # 形状: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75430a01-ef9c-426a-aca0-664689c4f461",
   "metadata": {},
   "source": [
    "- 如前几章所述，对于每个输入标记，都有一个输出向量\n",
    "- 由于我们向模型提供了具有 4 个输入标记的文本样本，因此输出由上面的 4 个二维输出向量组成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/input-and-output.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
   "metadata": {},
   "source": [
    "- 在第 3 章中，我们讨论了注意力机制，它将每个输入标记连接到另一个输入标记\n",
    "- 在第 3 章中，我们还介绍了类 GPT 模型中使用的因果注意力掩模； 这个因果掩码让当前标记只关注当前和之前的标记位置\n",
    "- 基于这种因果注意机制，第四个（最后一个）标记包含所有标记中最多的信息，因为它是唯一包含所有其他标记信息的标记\n",
    "- 因此，我们对最后一个标记特别感兴趣，我们将针对垃圾邮件分类任务对其进行微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
    "outputId": "e79eb155-fa1f-46ed-ff8c-d828c3a3fabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/attention-mask.webp\" width=200px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
   "metadata": {},
   "source": [
    "- 在解释损失计算之前，我们先简单看一下模型输出是如何转化为类标签的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
   "metadata": {},
   "source": [
    "- 与第5章类似，我们通过`softmax` 函数将输出（logits）转换为概率分数，然后通过`argmax` 函数获得最大概率值的索引位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a6f02-307e-4147-a416-14d115bf8179",
   "metadata": {},
   "source": [
    "- 请注意，softmax 函数在这里是可选的，如第 5 章所述，因为最大的输出对应于最大的概率分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
   "metadata": {},
   "source": [
    "- 我们可以应用这个概念来计算所谓的分类准确性，即计算给定数据集中正确预测的百分比\n",
    "- 为了计算分类准确率，我们可以将前面基于`argmax`的预测代码应用于数据集中的所有示例，并计算正确预测的比例，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # 最后输出标记的 Logits\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165fe46-a284-410b-957f-7524877d1a1a",
   "metadata": {},
   "source": [
    "- 让我们应用该函数来计算不同数据集的分类准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # nn.Module 类不需要分配 model = model.to(device)\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30345e2a-afed-4d22-9486-f4010f90a871",
   "metadata": {},
   "source": [
    "- 正如我们所看到的，预测准确率不是很好，因为我们还没有对模型进行微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
   "metadata": {},
   "source": [
    "- 在开始微调（/训练）之前，我们首先必须定义训练期间要优化的损失函数\n",
    "- 目标是最大化模型的垃圾邮件分类准确率； 然而，分类准确率不是一个可微函数\n",
    "- 因此，我们最小化交叉熵损失作为最大化分类准确率的代理（您可以在我免费提供的[深度学习简介](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression)）的第8讲中了解有关此主题的更多信息\n",
    "- `calc_loss_batch` 函数与第 5 章中的相同，只是我们只对优化最后一个标记 `model(input_batch)[:, -1, :]` 而不是所有标记 `model(input_batch)` 感兴趣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
   "metadata": {
    "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # 最后输出标记的 Logits\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
   "metadata": {},
   "source": [
    "`calc_loss_loader` 与第 5 章中的完全相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果 num_batches 超过数据加载器中的批次数，则减少批次数以匹配数据加载器中的批次总数\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56826ecd-6e74-40e6-b772-d3541e585067",
   "metadata": {},
   "source": [
    "- 使用`calc_closs_loader`，我们在开始训练之前计算初始训练、验证和测试集损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
    "outputId": "49df8648-9e38-4314-854d-9faacd1b2e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # 禁用梯度跟踪以提高效率，因为我们还没有进行训练\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
   "metadata": {},
   "source": [
    "- 在下一节中，我们训练模型以提高损失值，从而提高分类准确性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
   "metadata": {
    "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
   },
   "source": [
    "## 6.7 根据监督数据微调模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
   "metadata": {},
   "source": [
    "- 在本节中，我们定义并使用训练函数来提高模型的分类准确率\n",
    "- 下面的`train_classifier_simple`函数实际上与我们在第 5 章中用于预训练模型的`train_model_simple`函数相同\n",
    "- 唯一的两个区别是我们现在\n",
    "   1. 跟踪看到的训练示例的数量（`examples_seen`）而不是看到的示例的数量\n",
    "   2. 计算每个时期后的准确率，而不是在每个时期后打印示例文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/training-loop.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "Csbr60to50FL",
   "metadata": {
    "id": "Csbr60to50FL"
   },
   "outputs": [],
   "source": [
    "# 总体与第 5 章中的 `train_model_simple` 相同\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter, tokenizer):\n",
    "    # 初始化列表以跟踪损失和看到的示例\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # 主要的训练循环\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 将模型设置为训练模式\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # 重置上一个 epoch 的损失梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # 计算损失梯度\n",
    "            optimizer.step() # 使用损失梯度更新模型权重\n",
    "            examples_seen += input_batch.shape[0] # 新功能：跟踪示例而不是标记\n",
    "            global_step += 1\n",
    "\n",
    "            # 可选的评估步骤\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # 计算每个 epoch 后的准确率\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
   "metadata": {},
   "source": [
    "- `train_classifier_simple` 中使用的 `evaluate_model` 函数与我们在第 5 章中使用的函数相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
   "metadata": {},
   "source": [
    "- 在 M3 MacBook Air 笔记本电脑上训练大约需要 5 分钟，在 V100 或 A100 GPU 上训练不到半分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "X7kU3aAj7vTJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7kU3aAj7vTJ",
    "outputId": "504a033e-2bf8-41b5-a037-468309845513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 14.25 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261bf90-3ce7-4591-895a-044a05538f30",
   "metadata": {},
   "source": [
    "- 与第 5 章类似，我们使用 matplotlib 绘制训练集和验证集的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cURgnDqdCeka",
   "metadata": {
    "id": "cURgnDqdCeka"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # 绘制针对 epoch 的训练和验证损失\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # 为所见示例创建第二个 x 轴\n",
    "    ax2 = ax1.twiny()  # 创建共享相同 y 轴的第二个 x 轴\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # 用于对齐刻度的不可见图\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # 调整布局以腾出空间\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "OIqRt466DiGk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "OIqRt466DiGk",
    "outputId": "b16987cf-0001-4652-ddaf-02f7cffc34db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
   "metadata": {},
   "source": [
    "- 综上所述，根据向下的斜率，我们看到模型学习得很好\n",
    "- 此外，训练和验证损失非常接近这一事实表明模型不会过度拟合训练数据\n",
    "- 同样，我们可以绘制下面的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "yz8BIsaF0TUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "yz8BIsaF0TUo",
    "outputId": "3a7ed967-1f2a-4c6d-f4a3-0cc8cc9d6c5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAEiCAYAAADONmoUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABdB0lEQVR4nO3deVhU1f/A8fcMOOyrIIIiouKuiBthbrmESyRmaWaJS/rTXDPTLPcWysosNU0tbXNPzW+4RLjvKyou5IKiCLjLomwz9/fH5OgIKoPoIHxezzPPM3Puued+5oh8uPeee45KURQFIYQQQjx1anMHIIQQQpRUkoSFEEIIM5EkLIQQQpiJJGEhhBDCTCQJCyGEEGYiSVgIIYQwE0nCQgghhJlIEhZCCCHMRJKwEEIIYSaShIUQeWrZsiXDhw83dxhCFGuShIV4Qnr16oVKpcr1ateunblDE0IUEZbmDkCI4qxdu3bMnz/fqMzKyspM0Qghiho5ExbiCbKysqJs2bJGLxcXFwA2bdqERqNh69athvpTpkyhTJkyJCcnA7Bu3TqaNm2Ks7MzpUuX5qWXXuL06dOG+mfPnkWlUrF06VKaNWuGjY0NjRo14t9//2Xv3r00bNgQe3t72rdvz+XLlw379erVi9DQUCZNmoS7uzuOjo4MGDCArKysB36XzMxMRo4cSbly5bCzsyMwMJBNmzYZtp87d46QkBBcXFyws7OjVq1arFmz5oHtff/99/j5+WFtbY2HhwevvvqqYZtOpyM8PBxfX19sbGzw9/dn+fLlRvvHxMTQvn177O3t8fDw4K233uLKlSuG7S1btmTo0KGMGjUKV1dXypYty8SJEx8YjxDmIElYCDO5c8/1rbfe4ubNmxw8eJBx48Yxb948PDw8AEhPT2fEiBHs27ePqKgo1Go1nTt3RqfTGbU1YcIExo4dy4EDB7C0tOSNN95g1KhRfPvtt2zdupVTp04xfvx4o32ioqI4fvw4mzZtYtGiRaxYsYJJkyY9MN7Bgwezc+dOFi9ezOHDh3nttddo164dJ0+eBGDQoEFkZmayZcsWjhw5whdffIG9vX2ebe3bt4+hQ4cyefJkYmNjWbduHc2bNzdsDw8P55dffmH27NkcPXqUd999lzfffJPNmzcDcOPGDVq1akVAQAD79u1j3bp1JCcn07VrV6Pj/Pzzz9jZ2bF7926mTJnC5MmTiYyMzOe/kBBPgSKEeCLCwsIUCwsLxc7Ozuj16aefGupkZmYq9erVU7p27arUrFlT6dev30PbvHz5sgIoR44cURRFUeLi4hRAmTdvnqHOokWLFECJiooylIWHhyvVqlUzis3V1VVJT083lM2aNUuxt7dXtFqtoiiK0qJFC2XYsGGKoijKuXPnFAsLCyUhIcEontatWytjxoxRFEVR6tSpo0ycODFfffPHH38ojo6OSkpKSq5tGRkZiq2trbJjxw6j8r59+yrdu3dXFEVRPv74Y+XFF1802n7+/HkFUGJjYw3xN23a1KhOo0aNlNGjR+crRiGeBrknLMQT9MILLzBr1iyjMldXV8N7jUbD77//Tt26dfHx8eGbb74xqnvy5EnGjx/P7t27uXLliuEMOD4+ntq1axvq1a1b1/D+zll0nTp1jMouXbpk1La/vz+2traGz0FBQaSlpXH+/Hl8fHyM6h45cgStVkvVqlWNyjMzMyldujQAQ4cOZeDAgfz999+0adOGLl26GMV1r7Zt2+Lj40OlSpVo164d7dq1o3Pnztja2nLq1Clu3bpF27ZtjfbJysoiICAAgEOHDrFx48Y8z7RPnz5tiPP+43t6eubqByHMSZKwEE+QnZ0dVapUeWidHTt2AHDt2jWuXbuGnZ2dYVtISAg+Pj7MnTsXLy8vdDodtWvXznXvtlSpUob3KpUqz7L7L2GbIi0tDQsLC/bv34+FhYXRtjuJ8O233yY4OJiIiAj+/vtvwsPD+frrrxkyZEiu9hwcHDhw4ACbNm3i77//Zvz48UycOJG9e/eSlpYGQEREBOXKlTPa786gtrS0NEJCQvjiiy9yte3p6Wl4f28fwOP3gxCFTZKwEGZ0+vRp3n33XebOncuSJUsICwvjn3/+Qa1Wc/XqVWJjY5k7dy7NmjUDYNu2bYV27EOHDnH79m1sbGwA2LVrF/b29nh7e+eqGxAQgFar5dKlS4ZY8uLt7c2AAQMYMGAAY8aMYe7cuXkmYQBLS0vatGlDmzZtmDBhAs7OzmzYsIG2bdtiZWVFfHw8LVq0yHPf+vXr88cff1CxYkUsLeXXmHh2yU+vEE9QZmYmSUlJRmWWlpa4ubmh1Wp58803CQ4Opnfv3rRr1446derw9ddf8/777+Pi4kLp0qWZM2cOnp6exMfH88EHHxRabFlZWfTt25exY8dy9uxZJkyYwODBg1Grc4/XrFq1Kj169KBnz558/fXXBAQEcPnyZaKioqhbty4dO3Zk+PDhtG/fnqpVq3L9+nU2btxIjRo18jz2X3/9xZkzZ2jevDkuLi6sWbMGnU5HtWrVcHBwYOTIkbz77rvodDqaNm3KzZs32b59O46OjoSFhTFo0CDmzp1L9+7dDaOfT506xeLFi5k3b16us3UhiipJwkI8QevWrTO6PApQrVo1Tpw4waeffsq5c+f466+/AP1l1Dlz5tC9e3defPFF/P39Wbx4MUOHDqV27dpUq1aN7777jpYtWxZKbK1bt8bPz4/mzZuTmZlJ9+7dH/oIz/z58/nkk0947733SEhIwM3Njeeee46XXnoJAK1Wy6BBg7hw4QKOjo60a9cu1z3uO5ydnVmxYgUTJ04kIyMDPz8/Fi1aRK1atQD4+OOPcXd3Jzw8nDNnzuDs7Ez9+vX58MMPAfDy8mL79u2MHj2aF198kczMTHx8fGjXrl2ef0QIUVSpFEVRzB2EEOLp6tWrFzdu3GDVqlXmDkWIEk3+ZBRCCCHMRJKwEEIIYSZyOVoIIYQwEzkTFkIIIcxEkrAQQghhJpKEhRBCCDORJFxAM2fOpGLFilhbWxMYGMiePXvMHdITsWXLFkJCQvDy8kKlUuV6pEVRFMaPH4+npyc2Nja0adPGsKrOHdeuXaNHjx44Ojri7OxM3759DVMT3nH48GGaNWuGtbU13t7eTJky5Ul/tccWHh5Oo0aNcHBwoEyZMoSGhhIbG2tUJyMjg0GDBlG6dGns7e3p0qWLYZnCO+Lj4+nYsSO2traUKVOG999/n5ycHKM6mzZton79+lhZWVGlShUWLFjwpL/eY5k1axZ169bF0dERR0dHgoKCWLt2rWF7Se2XB/n8889RqVQMHz7cUFaS+2jixImoVCqjV/Xq1Q3bi1XfmHX5iGfU4sWLFY1Go/z000/K0aNHlX79+inOzs5KcnKyuUMrdGvWrFE++ugjZcWKFQqgrFy50mj7559/rjg5OSmrVq1SDh06pLz88suKr6+vcvv2bUOddu3aKf7+/squXbuUrVu3KlWqVDGshqMoinLz5k3Fw8ND6dGjhxITE6MsWrRIsbGxUX744Yen9TULJDg4WJk/f74SExOjREdHKx06dFAqVKigpKWlGeoMGDBA8fb2VqKiopR9+/Ypzz33nNKkSRPD9pycHKV27dpKmzZtlIMHDypr1qxR3NzcDCsTKYqinDlzRrG1tVVGjBihHDt2TJk+fbpiYWGhrFu37ql+X1OsXr1aiYiIUP79918lNjZW+fDDD5VSpUopMTExiqKU3H7Jy549e5SKFSsqdevWNaxapSglu48mTJig1KpVS0lMTDS8Ll++bNhenPpGknABNG7cWBk0aJDhs1arVby8vJTw8HAzRvXk3Z+EdTqdUrZsWeXLL780lN24cUOxsrJSFi1apCiKohw7dkwBlL179xrqrF27VlGpVIZl8b7//nvFxcVFyczMNNQZPXq00dJ7z4JLly4pgLJ582ZFUfR9UapUKWXZsmWGOsePH1cAZefOnYqi6P/IUavVSlJSkqHOrFmzFEdHR0N/jBo1SqlVq5bRsbp166YEBwc/6a9UqFxcXJR58+ZJv9wjNTVV8fPzUyIjI42WjizpfTRhwgTF398/z23FrW/kcrSJsrKy2L9/P23atDGUqdVq2rRpw86dO80Y2dMXFxdHUlKSUV84OTkRGBho6IudO3fi7OxMw4YNDXXatGmDWq1m9+7dhjrNmzdHo9EY6gQHBxMbG8v169ef0rd5fDdv3gTuLlW4f/9+srOzjfqnevXqVKhQwah/6tSpY1h+EPTfPSUlhaNHjxrq3NvGnTrPys+bVqtl8eLFpKenExQUJP1yj0GDBtGxY8dc30P6SL+Mp5eXF5UqVaJHjx7Ex8cDxa9vJAmb6MqVK2i1WqN/XNCv13r/RP3F3Z3v+7C+SEpKokyZMkbbLS0tcXV1NaqTVxv3HqOo0+l0DB8+nOeff96wzm9SUhIajQZnZ2ejuvf3z6O++4PqpKSkcPv27SfxdQrFkSNHsLe3x8rKigEDBrBy5Upq1qxZ4vvljsWLF3PgwAHCw8NzbSvpfRQYGMiCBQtYt24ds2bNIi4ujmbNmpGamlrs+kYWcBCiEAwaNIiYmJhCXWrwWVetWjWio6O5efMmy5cvJywsjM2bN5s7rCLh/PnzDBs2jMjISKytrc0dTpHTvn17w/u6desSGBiIj48PS5cuNSy9WVzImbCJ3NzcsLCwyDUSLzk5mbJly5opKvO4830f1hdly5bl0qVLRttzcnK4du2aUZ282rj3GEXZ4MGD+euvv9i4cSPly5c3lJctW5asrCxu3LhhVP/+/nnUd39QHUdHxyL9C0mj0VClShUaNGhAeHg4/v7+fPvttyW+X0B/SfXSpUvUr18fS0tLLC0t2bx5M9999x2WlpZ4eHiU+D66l7OzM1WrVuXUqVPF7udHkrCJNBoNDRo0ICoqylCm0+mIiooiKCjIjJE9fb6+vpQtW9aoL1JSUti9e7ehL4KCgrhx4wb79+831NmwYQM6nY7AwEBDnS1btpCdnW2oExkZSbVq1XBxcXlK38Z0iqIwePBgVq5cyYYNG/D19TXa3qBBA0qVKmXUP7GxscTHxxv1z5EjR4z+UImMjMTR0ZGaNWsa6tzbxp06z9rPm06nIzMzU/oF/TKSR44cITo62vBq2LAhPXr0MLwv6X10r7S0NE6fPo2np2fx+/l5qsPAionFixcrVlZWyoIFC5Rjx44p/fv3V5ydnY1G4hUXqampysGDB5WDBw8qgDJ16lTl4MGDyrlz5xRF0T+i5OzsrPz555/K4cOHlU6dOuX5iFJAQICye/duZdu2bYqfn5/RI0o3btxQPDw8lLfeekuJiYlRFi9erNja2hb5R5QGDhyoODk5KZs2bTJ6lOLWrVuGOgMGDFAqVKigbNiwQdm3b58SFBSkBAUFGbbfeZTixRdfVKKjo5V169Yp7u7ueT5K8f777yvHjx9XZs6cWeQfM/nggw+UzZs3K3Fxccrhw4eVDz74QFGpVMrff/+tKErJ7ZeHuXd0tKKU7D567733lE2bNilxcXHK9u3blTZt2ihubm7KpUuXFEUpXn0jSbiApk+frlSoUEHRaDRK48aNlV27dpk7pCdi48aNCpDrFRYWpiiK/jGlcePGKR4eHoqVlZXSunVrJTY21qiNq1evKt27d1fs7e0VR0dHpXfv3kpqaqpRnUOHDilNmzZVrKyslHLlyimff/750/qKBZZXvwDK/PnzDXVu376tvPPOO4qLi4tia2urdO7cWUlMTDRq5+zZs0r79u0VGxsbxc3NTXnvvfeU7OxsozobN25U6tWrp2g0GqVSpUpGxyiK+vTpo/j4+CgajUZxd3dXWrdubUjAilJy++Vh7k/CJbmPunXrpnh6eioajUYpV66c0q1bN+XUqVOG7cWpb2QVJSGEEMJM5J6wEEIIYSaShIUQQggzkSQshBBCmIkkYSGEEMJMJAkLIYQQZiJJWAghhDATScKPITMzk4kTJ5KZmWnuUIok6Z8Hk755OOmfh5P+ebBnrW/kOeHHkJKSgpOTEzdv3sTR0dHc4RQ50j8PJn3zcNI/Dyf982DPWt/ImbAQQghhJpKEhRBCCDMpcesJ5+TkcPDgQTw8PFCrH+9vkNTUVAASEhJISUkpjPCKFemfB5O+eTjpn4eT/nmwotA3Op2O5ORkAgICsLR8eJotcfeE9+7dS+PGjc0dhhBCiGJuz549NGrU6KF1StyZsIeHB6DvHE9PTzNHI4QQorhJTEykcePGhnzzMCUuCd+5BO3p6Un58uXNHI0QQojiKj+3PGVglhBCCGEmZk3CW7ZsISQkBC8vL1QqFatWrXrkPps2baJ+/fpYWVlRpUoVFixY8MTjFEIIIZ4Esybh9PR0/P39mTlzZr7qx8XF0bFjR1544QWio6MZPnw4b7/9NuvXr3/CkQohhBCFz6z3hNu3b0/79u3zXX/27Nn4+vry9ddfA1CjRg22bdvGN998Q3BwcKHGptVqyc7OLtQ2hSgKNBrNYz+eJ4QoHM/UwKydO3fSpk0bo7Lg4GCGDx9eaMdQFIWkpCRu3LhRaG0KUZSo1Wp8fX3RaDTmDkU8QEa2ln1nr5Ot1Zk7lBLH3cGK2uWcntrxnqkknJSUlGvIt4eHBykpKdy+fRsbG5tc+2RmZhpN5H3nQe6HHePGjRuUKVMGW1tbVCpV4QQvRBGg0+m4ePEiiYmJVKhQQX6+i6ANJ5KZsPoo56/dNncoJdJLdT2Z8Ub9p3a8ZyoJF0R4eDiTJk3KV12tVmtIwKVLl37CkQlhHu7u7ly8eJGcnBxKlSpl7nDEfy5cv8Wk/x0j8lgyAG72Grycc59YiCergqvtUz3eM5WEy5YtS3JyslFZcnIyjo6OeZ4FA4wZM4YRI0YYPickJFCzZs086965B2xr+3T/EYR4mu5chtZqtZKEi4DMHC3ztsYxfcNJMrJ1WKpV9G3qy9DWfthZPVO/okUBPFP/wkFBQaxZs8aoLDIykqCgoAfuY2VlhZWVleFzfuYSlUt0ojiTn++iY/upK4z7M4Yzl9MBCPR15ePQ2lT1cDBzZOJpMWsSTktL49SpU4bPcXFxREdH4+rqSoUKFRgzZgwJCQn88ssvAAwYMIAZM2YwatQo+vTpw4YNG1i6dCkRERHm+gpCCGGy5JQMPv7rGH8dTgTAzd6KsR1r0Kmel/yRVMKY9TmFffv2ERAQQEBAAAAjRowgICCA8ePHA/r5N+Pj4w31fX19iYiIIDIyEn9/f77++mvmzZtX6I8nCb2KFSsybdq0fNfftGkTKpVKRpYL8QA5Wh3ztp6h9deb+etwImoV9GpSkaj3WhAaUE4ScAlk1jPhli1b8rBFnPKaDatly5YcPHjwCUb17HnUf9wJEyYwceJEk9vdu3cvdnZ2+a7fpEkTEhMTcXJ6esP7hXhW7D17jXGrYjiRpH9CI6CCMx93qv1UH4cRRc8zdU9Y5C0xMdHwfsmSJYwfP57Y2FhDmb29veG9oihotdpHrnEJ+lG0ptBoNJQtW9akfYqLrKwsee5W5OlKWibha07wx4ELALjYluKD9tV5rYE3arWc+ZZ0Mm1OMVC2bFnDy8nJCZVKZfh84sQJHBwcWLt2LQ0aNMDKyopt27Zx+vRpOnXqhIeHB/b29jRq1Ih//vnHqN37L0erVCrmzZtH586dsbW1xc/Pj9WrVxu23385esGCBTg7O7N+/Xpq1KiBvb097dq1M/qjIScnh6FDh+Ls7Ezp0qUZPXo0YWFhhIaGPvD7Xr16le7du1OuXDlsbW2pU6cOixYtMqqj0+mYMmUKVapUwcrKigoVKvDpp58atl+4cIHu3bvj6uqKnZ0dDRs2ZPfu3QD06tUr1/GHDx9Oy5YtDZ9btmzJ4MGDGT58OG5uboZbIlOnTqVOnTrY2dnh7e3NO++8Q1pamlFb27dvp2XLltja2uLi4kJwcDDXr1/nl19+oXTp0kbPtQOEhoby1ltvPbA/RNGk1Sn8uuscrb7aZEjA3Rt7s+G9lnRrVEESsAAkCT+Soijcysoxy+thl+pN9cEHH/D5559z/Phx6tatS1paGh06dCAqKoqDBw/Srl07QkJCjO7B52XSpEl07dqVw4cP06FDB3r06MG1a9ceWP/WrVt89dVX/Prrr2zZsoX4+HhGjhxp2P7FF1/w+++/M3/+fLZv305KSsojF/LIyMigQYMGREREEBMTQ//+/XnrrbfYs2ePoc6YMWP4/PPPGTduHMeOHWPhwoWGiV7S0tJo0aIFCQkJrF69mkOHDjFq1Ch0OtNmJ/r555/RaDRs376d2bNnA/rZqL777juOHj3Kzz//zIYNGxg1apRhn+joaFq3bk3NmjXZuXMn27ZtIyQkBK1Wy2uvvYZWqzX6w+bSpUtERETQp08fk2IT5nXo/A06f7+dcatiSMnIoZaXIyveaUL4K3VxsZMrJuIuuRz9CLeztdQcb54FIo5NDsZWUzj/RJMnT6Zt27aGz66urvj7+xs+f/zxx6xcuZLVq1czePDgB7bTq1cvunfvDsBnn33Gd999x549e2jXrl2e9bOzs5k9ezaVK1cGYPDgwUyePNmwffr06YwZM4bOnTsDMGPGjFyPod2vXLlyRol8yJAhrF+/nqVLl9K4cWNSU1P59ttvmTFjBmFhYQBUrlyZpk2bArBw4UIuX77M3r17cXV1BaBKlSoPPWZe/Pz8mDJlilHZvVOoVqxYkU8++YQBAwbw/fffAzBlyhQaNmxo+AxQq1Ytw/s33niD+fPn89prrwHw22+/UaFCBaOzcFF03biVxZfrY1m4Jx5FAQdrS0a+WI03n/PBQs58RR4kCZcQDRs2NPqclpbGxIkTiYiIIDExkZycHG7fvv3IM+G6desa3tvZ2eHo6MilS5ceWN/W1taQgAE8PT0N9W/evElycjKNGzc2bLewsKBBgwYPPSvVarV89tlnLF26lISEBLKyssjMzDRMsnL8+HEyMzNp3bp1nvtHR0cTEBBgSMAF1aBBg1xl//zzD+Hh4Zw4cYKUlBRycnLIyMjg1q1b2NraEh0dbUiweenXrx+NGjUiISGBcuXKsWDBAnr16iWjZos4nU5h+YELfL72BNfSswB4JaAcYzrUwN3B6hF7i5JMkvAj2JSy4Nhk8zwCZVPKotDaun+U88iRI4mMjOSrr76iSpUq2NjY8Oqrr5KVlfXQdu6fYUmlUj00YeZV/3Evs3/55Zd8++23TJs2zXD/dfjw4YbYHzR72h2P2q5Wq3PFmNeKWvf36dmzZ3nppZcYOHAgn376Ka6urmzbto2+ffuSlZWFra3tI48dEBCAv78/v/zyCy+++CJHjx6V5+CLuGMXUxj3Zwz7z10HoKqHPR93qk1gJZn6VjyaJOFHUKlUhXZJuCjZvn07vXr1MlwGTktL4+zZs081BicnJzw8PNi7dy/NmzcH9Ge5Bw4coF69eg/cb/v27XTq1Ik333wT0A/C+vfffw3Tkfr5+WFjY0NUVBRvv/12rv3r1q3LvHnzuHbtWp5nw+7u7sTExBiVRUdHP3KKx/3796PT6fj6668NSwUuXbo017GjoqIeOp/522+/zbRp00hISKBNmzZ4e3s/9LjCPFIzsvkm8iQ/7zyLVqdgq7FgeBs/ej/vSymLxxxuo9PB9TjQ5rGcqlM5sPpvRq3bNyA1CTS24Fzhbp3L/4Ji4gpMDh5g46J/n5kGNy+ApRW4+t6tc/V03jE9jJ072P33B0n2bbh+DtSW4HbPLaDrZyE7w7R2bVz0MYM+pqunQaUC92p369w4D1np+W/T2gkcPU2L4zEVv+wi8sXPz48VK1YQEhKCSqVi3LhxJg9MKgxDhgwhPDycKlWqUL16daZPn87169cfevnVz8+P5cuXs2PHDlxcXJg6dSrJycmGJGxtbc3o0aMZNWoUGo2G559/nsuXL3P06FH69u1L9+7d+eyzzwgNDSU8PBxPT08OHjyIl5cXQUFBtGrVii+//JJffvmFoKAgfvvtN2JiYgyTyjxIlSpVyM7OZvr06YSEhBgN2LpjzJgx1KlTh3feeYcBAwag0WjYuHEjr732Gm5uboD+vvDIkSOZO3euYbY4UXQoisLqQxf5NOI4l1L1I9k71vFk7Es18HR6zAUXsjPgyFLYMQOuxOZdp/tiqPbfOuz/roOV/weVW8NbK+7WmfsCZKXlvf+DvDwd6vfUv4/fBb93AU9/+L8td+v89oo+YZqi9QRo9t/8/ZdPwJyW4FgORhy7W2d5X0jYZ1q7QYMh+L8nHtKS4ftAsLCCcffcHlszUt9H+RXwJnSaaVocj0mScAk1depU+vTpQ5MmTXBzc2P06NH5mle7sI0ePZqkpCR69uyJhYUF/fv3Jzg4GAuLB1+KHzt2LGfOnCE4OBhbW1v69+9PaGgoN2/eNNQZN24clpaWjB8/nosXL+Lp6cmAAQMA/fPMf//9N++99x4dOnQgJyeHmjVrMnOm/j9fcHAw48aNY9SoUWRkZNCnTx969uzJkSNHHvpd/P39mTp1Kl988QVjxoyhefPmhIeH07NnT0OdqlWr8vfff/Phhx/SuHFjbGxsCAwMNAx2A/0Vgi5duhAREfHQR7XE03fqUirj/zzKjtNXAfB1s2PSy7VoXtW0Z+pzuXUN9v0Iu+dA+n9JxMIKrOxz17W454qMhQZsS4O1o3EdG1f9WawpLK3vadfyv3bvm0jExgUyH74cbC6l7vnDRP1fu3fOuO+wdtKXm9TuPQvtqNT6/S3u+85WDqa1q8mjv58wlVKYz8E8Ay5cuIC3tzfnz5+nfPnyRtsyMjKIi4vD19cXa2vrB7QgniSdTkeNGjXo2rUrH3/8sbnDMZvWrVtTq1Ytvvvuu0JvW37OTXcrK4fpG04xb+sZsrUKVpZqBr9Qhf4tKmFl+RhjN66fhZ3fw8FfIfuWvsyxPDw3UH9Wen9yFc+Eh+WZ+8mZsDCrc+fO8ffff9OiRQsyMzOZMWMGcXFxvPHGG+YOzSyuX7/Opk2b2LRpk9FjTMI8FEVh/dFkPv7rGAk3bgPQpkYZJoTUwrsw1p3dMQP2ztW/96gDzw+FWp2Nz3ZFsSZJWJiVWq1mwYIFjBw5EkVRqF27Nv/88w81atQwd2hmERAQwPXr1/niiy+oVq3ao3cQT8y5q+lMWH2UTbGXASjnbMPEl2vRtqZHwRrU6eBUpP5+aNna+rKgd/QDsIIGQ6WW+oFFokSRJCzMytvbm+3bt5s7jCLjaY9QF7llZGuZvfk03286TVaOjlIWKv6veWUGvVAFG81jXHre8DFsmwo1XoZuv+rLXCvBm38UTuDimSRJWAgh/rMx9hITVx/l3FX9/dmmVdyY1KkWld0LMGDn1jXIybz7yEvdrrD3R33iVRQ56xWAJGEhhODijdtM/t8x1h1NAsDD0YpxL9WkYx1P02cru34Wds2CA79CjRB45Qd9eZkaMDLWeLSwKPEkCQshSqysHB0/bovju6iT3M7WYqFW0ef5igxrUxV7KxN/PSYcgB3T4diquxNlXIkFbY7+kR+QBCxykSQshCiRdpy+wvg/j3Lqkn5Si8YVXZkcWovqZU14LOjOYKsd0+Hs1rvllVtBk6Ey2Eo8kiRhIUSJciklg0/XHOfP6IsAuNlrGNO+Bq/UL5f/S885mXB4KeycoZ8FCvQTUdR+FZoMuTv6WYhHkCQshCgRcrQ6ftl5jm8i/yU1MweVCt56zof3XqyGk00+n8u9fR32/QS7f9BPlQhg5QgNekHgAP28zkKY4DFnGRfFScuWLXOthztt2rSH7qNSqVi1atVjH7uw2hEiL/vPXSdkxnYm/3WM1Mwc/L2dWT2oKZM71c5/AgZY0R+iJusTsGM5ePETeDcGXvxYErAoEDkTLgZCQkLIzs5m3brcE5Vv3bqV5s2bc+jQIaO1gPNj7969uZbre1wTJ05k1apVREdHG5UnJibi4uKS905CFNDVtEy+WHeCpfsuAOBkU4rR7arzeiNv1Op8XHq+eBCcvMFOv7gGjfpBSqL+knPtV2RmK/HYJAkXA3379qVLly5cuHAh1zyl8+fPp2HDhiYnYNAv6fe0lC1b9qkdqyjJyspCo9GYO4xiR6dTWLQ3ninrYrl5W7/0XreG3oxuXx1Xu3z295pRsOcHaDEaXvhQX+bXVv+SwVaikMjl6GLgpZdewt3dnQULFhiVp6WlsWzZMvr27cvVq1fp3r075cqVw9bWljp16rBo0aKHtnv/5eiTJ0/SvHlzrK2tqVmzJpGRkbn2GT16NFWrVsXW1pZKlSoxbtw4srP1vwQXLFjApEmTOHToECqVCpVKZYj5/svRR44coVWrVtjY2FC6dGn69+9PWtrdpdl69epFaGgoX331FZ6enpQuXZpBgwYZjpWX06dP06lTJzw8PLC3t6dRo0b8888/RnUyMzMZPXo03t7eWFlZUaVKFX788UfD9qNHj/LSSy/h6OiIg4MDzZo14/Tp00Duy/kAoaGh9OrVy6hPP/74Y3r27ImjoyP9+/d/ZL/d8b///Y9GjRphbW2Nm5ubYS3oyZMnU7t27oFA9erVY9y4cQ/sj+LqyIWbdJ61g49WxnDzdjY1PB35Y2AQX7xa9+EJOCcTsm7d/ewTpB9slXF3dS5UKknAolDJmXB+mbIw9B0WVnefD9TmgDZTv+TWvc8KPqhdTf4vA1taWtKzZ08WLFjARx99ZBjhuWzZMrRaLd27dyctLY0GDRowevRoHB0diYiI4K233qJy5co0btz4kcfQ6XS88soreHh4sHv3bm7evJkr4QA4ODiwYMECvLy8OHLkCP369cPBwYFRo0bRrVs3YmJiWLdunSH5OTk55WojPT2d4OBggoKC2Lt3L5cuXeLtt99m8ODBRn9obNy4EU9PTzZu3MipU6fo1q0b9erVo1+/fnl+h7S0NDp06MCnn36KlZUVv/zyCyEhIcTGxlKhgn5B9J49e7Jz506+++47/P39iYuL48qVKwAkJCTQvHlzWrZsyYYNG3B0dGT79u3k5OQ8sv/u9dVXXzF+/HgmTJiQr34DiIiIoHPnznz00Uf88ssvZGVlsWbNGgD69OnDpEmT2Lt3L40aNQLg4MGDHD58mBUrVuQOoJi6eSubr/6O5bfd51AUsLey5L0Xq/LWcz5YWjzkfOPewVbPDYSm7+rLa7wMww7LvV7xZCklzPnz5xVAOX/+fK5tt2/fVo4dO6bcvn07944THE1/xay4u3/MCn3ZTx2M2/3CN+99TXT8+HEFUDZu3Ggoa9asmfLmm28+cJ+OHTsq7733nuFzixYtlGHDhhk++/j4KN98842iKIqyfv16xdLSUklISDBsX7t2rQIoK1eufOAxvvzyS6VBgwaGzxMmTFD8/f1z1bu3nTlz5iguLi5KWlqaYXtERISiVquVpKQkRVEUJSwsTPHx8VFycnIMdV577TWlW7duD4wlL7Vq1VKmT5+uKIqixMbGKoASGRmZZ90xY8Yovr6+SlZWVp7b7+8/RVGUTp06KWFhYYbPPj4+Smho6CPjur/fgoKClB49ejywfvv27ZWBAwcaPg8ZMkRp2bJlnnUf+nP+DNLpdMryfeeV+pP/VnxG/6X4jP5LGbrogJJ88xHf79pZRVkzWlE+8bz7/+6Hloqi0z2dwEWx9bA8cz85Ey4mqlevTpMmTfjpp59o2bIlp06dYuvWrUyePBkArVbLZ599xtKlS0lISCArK4vMzExsbfO3HNvx48fx9vbGy8vLUBYUFJSr3pIlS/juu+84ffo0aWlp5OTk4Oho2pqox48fx9/f32hQ2PPPP49OpyM2NhYPD/0qNrVq1cLC4u6E+p6enhw5cuSB7aalpTFx4kQiIiJITEwkJyeH27dvEx8fD0B0dDQWFha0aNEiz/2jo6Np1qwZpUo93mCchg0b5ip7VL9FR0c/8AwfoF+/fvTp04epU6eiVqtZuHAh33zzzWPF+Sw4kZTC+FVH2XP2GgBVytgzuVMtmlR2e/BOFw/qJ9c4ugoUrb6sTK3/lhF8RS43i6dKknB+fXjR9H0srO6+rx6ib0N132Wx4Q9OGqbq27cvQ4YMYebMmcyfP5/KlSsbEsqXX37Jt99+y7Rp06hTpw52dnYMHz6crKysQjv+zp076dGjB5MmTSI4OBgnJycWL17M119/XWjHuNf9yVClUqHT6R5Yf+TIkURGRvLVV19RpUoVbGxsePXVVw19YGPz8CkFH7VdrVajKIpRWV73qO8fcZ6ffnvUsUNCQrCysmLlypVoNBqys7N59dVXH7rPsywtM4dpkf8yf8dZtDoFm1IWDGvjR5/nfdFY5nHpWaeDU//Aju+MZ7aq1FI/s1XlVpJ8hVlIEs4vE+7R5snC8u794cJs9x5du3Zl2LBhLFy4kF9++YWBAwca7g9v376dTp068eabbwL6e7z//vsvNWvWzFfbNWrU4Pz58yQmJuLpqV8VZteuXUZ1duzYgY+PDx999JGh7Ny5c0Z1NBoNWq32kcdasGAB6enphoS1fft21Gr1Y62xu337dnr16mUY0JSWlma0dGCdOnXQ6XRs3ryZNm3a5Nq/bt26/Pzzz2RnZ+d5Nuzu7k5iYqLhs1arJSYmhhdeeOGhceWn3+rWrUtUVBS9e/fOsw1LS0vCwsKYP38+Go2G119//ZGJ+1mkKAoRRxL5+K9jJKdkAtCuVlnGhdSknHMe3zcnE44s05/53pnZSmUBtbvoHzPyNP2pASEKk4yOLkbs7e3p1q0bY8aMITEx0WhUrp+fH5GRkezYsYPjx4/zf//3fyQnJ+e77TZt2lC1alXCwsI4dOgQW7duNUoad44RHx/P4sWLOX36NN999x0rV640qlOxYkXi4uKIjo7mypUrZGZm5jpWjx49sLa2JiwsjJiYGDZu3MiQIUN46623DJeiC8LPz48VK1YQHR3NoUOHeOONN4zOnCtWrEhYWBh9+vRh1apVxMXFsWnTJpYuXQrA4MGDSUlJ4fXXX2ffvn2cPHmSX3/9ldjYWABatWpFREQEERERnDhxgoEDB3Ljxo18xfWofpswYQKLFi1iwoQJHD9+nCNHjvDFF18Y1Xn77bfZsGED69ato0+fPgXup6Lq9OU03vpxD4MXHiQ5JROf0rYs6N2I2W81yDsBA/zUDv4cpE/AGnsIGgzDDkGXuZKARZEgSbiY6du3L9evXyc4ONjo/u3YsWOpX78+wcHBtGzZkrJlyxIaGprvdtVqNStXruT27ds0btyYt99+m08//dSozssvv8y7777L4MGDqVevHjt27Mj1iEyXLl1o164dL7zwAu7u7nk+JmVra8v69eu5du0ajRo14tVXX6V169bMmDHDtM64z9SpU3FxcaFJkyaEhIQQHBxM/fr1jerMmjWLV199lXfeeYfq1avTr18/0tP1I9hLly7Nhg0bSEtLo0WLFjRo0IC5c+cazor79OlDWFgYPXv2pEWLFlSqVOmRZ8GQv35r2bIly5YtY/Xq1dSrV49WrVqxZ88eozp+fn40adKE6tWrExgY+DhdVaTcztLy1fpY2k3bwrZTV9BYqhnexo/1w5vTsloZ48o34vVPItxRKxQcPKHtZHj3KAR/Cs7eTzV+IR5Gpdx/E6uYu3DhAt7e3pw/fz7XxBYZGRnExcXh6+uLtbW1mSIUomAURcHPz4933nmHESNGPLDes/RzHnksmYmrj5Jw4zYAL1RzZ+LLtfApncdtnDXvw94f9We5tbvoy7Jv6y8/W8qEKOLpeVieuZ/cExaiGLh8+TKLFy8mKSnpgfeNnyXnr91i4uqjRJ24BEA5ZxvGh9TkxZoed1c6unP+cOezbWn9aOfze+4mYVm/VxRxkoSFKAbKlCmDm5sbc+bMeabn4M7M0fLD5jPM3HiKzBwdpSxUvN2sEkNaVcFW89+vq5ws/WCrnTOg9QSo1k5f3rg/VGsPnv7m+wJCmEiSsBDFQHG4q7Tl38tMWH2UuCv6e/BNKpdmcqfaVCljr69w+wbsn6+f2Sr1v1Hoe+feTcK2rvqXEM8QScJCCLNKvHmbj/86xpojSQCUcbBi7Es1Canrqb/0fCMeds2GAz9D1n/zhzt46tfvbdDLfIELUQgkCQshzCJbq2P+9jim/XOSW1laLNQqwoIq8m5bPxysS0HiIf3zvTErjGe2ajJEf89XBluJYkCScB4eNuuSEM+6onDpeteZq4z/M4Z/k/Vntg19XJjcqTY1PR3gVJR+Zqu4zXd3qNRSn3wrt5aZrUSxIkn4HhqNBrVazcWLF3F3d0ej0dwdiSlEMaAoCpcvX0alUj32HNgFcSk1g/A1J1h5MAEAVzsNY9pXp0v98qgVLcxpCYnR+sqGma0Gy2ArUWxJEr6HWq3G19eXxMRELl4swFzRQjwDVCoV5cuXN1r84knT6hR+23WOr9bHkpqZg0oFbzSuwPsvlMfZ+c5obksoUxOuntLf6w0cIBNriGJPkvB9NBoNFSpUICcn55FzHAvxLCpVqtRTTcAH4q8zblUMRy+mAFCnnBOfdKqF/4mv4fsF0GcdlK2tr9xmArQLBxvnpxafEOYkSTgPdy7VmeNynRDFxfX0LKasP8GiPecBcLS25P121XmjcQUs1CrYFQ9ZqRCz/G4SdihrxoiFePokCQshCpVOp7B033m+WHeC67eyAYUPqyXSi/+h8fsG1P+Ns2jxAQT0hCqtzRqvEOYkSVgIUWhiEm4y7s8YDsbfoBQ5DHY9wDuatdie0680xc6Z8NJU/XuPmvqXECWYJGEhxGNLychm6t//8svOs9gr6QzRbGSATSR2ty7DLfTLCNYPg+cGmjtUIYoUScJCiAJTFIVV0Ql8GnECTVoCYyzX8aZmEza6W5CJ8cxWMthKiFwkCQshCuTf5FTGrYoh7ewBPrKM4GXrnVigAx36R42aDIHar8rMVkI8hNrcAcycOZOKFStibW1NYGBgroXK75Wdnc3kyZOpXLky1tbW+Pv7s27duqcYrRAiPTOH8DXH6frteoZceI8Iqw/pbLFdn4B9W0CPP2DgDqj3hiRgIR7BrGfCS5YsYcSIEcyePZvAwECmTZtGcHAwsbGxlClTJlf9sWPH8ttvvzF37lyqV6/O+vXr6dy5Mzt27CAgIMAM30CIkkNRFNYeSeTjiOMk3swArCnvkIOSZYGq9isQNBi86pk7TCGeKSrFjBPJBgYG0qhRI2bMmAHo52z29vZmyJAhfPDBB7nqe3l58dFHHzFo0CBDWZcuXbCxseG3337L1zEvXLiAt7c358+fp3z58oXzRYQo5uKSr7Nr4Sc0vL6WLlkTcXJ1Y9LLtWjlmKhfPtC5grlDFKLIMCXPmHwmXLFiRfr06UOvXr2oUKHg//GysrLYv38/Y8aMMZSp1WratGnDzp0789wnMzMTa2trozIbGxu2bdv2wONkZmaSmZlp+JyamlrgmIUoUXKyuJim5adtcfyy8yz/s1iHnzqBb2scI+iNcViXsgA8zB2lEM80k+8JDx8+nBUrVlCpUiXatm3L4sWLjZJcfl25cgWtVouHh/F/Yg8PD5KSkvLcJzg4mKlTp3Ly5El0Oh2RkZGsWLGCxMTEBx4nPDwcJycnw6tmTXkuUYgHSkmEffNJ/ekVMj7z4aUp/2PetjiytAoRZfpzufU3vNBjzH8JWAjxuAqUhKOjo9mzZw81atRgyJAheHp6MnjwYA4cOPAkYjT49ttv8fPzo3r16mg0GgYPHkzv3r1Rqx/8NcaMGcPNmzcNr2PHjj3RGIV4pigKJB2BzVNQ5rwAU6vDX8NxiI/CWneLxhwlqFJp5vduxLuDhuLerA9YWpk7aiGKjQIPzKpfvz7169fn66+/5vvvv2f06NHMmjWLOnXqMHToUHr37v3QZQDd3NywsLAgOTnZqDw5OZmyZfOeP9bd3Z1Vq1aRkZHB1atX8fLy4oMPPqBSpUoPPI6VlRVWVnd/aaSkpJj4TYUoZnIy4ew2iF2rf6VcAODO/9ZoXWWidA3IrNKOQa1bU8fb2WyhClHcFTgJZ2dns3LlSubPn09kZCTPPfccffv25cKFC3z44Yf8888/LFy48IH7azQaGjRoQFRUFKGhoYB+YFZUVBSDBw9+6LGtra0pV64c2dnZ/PHHH3Tt2rWgX0OIkuPoSv3rVBRkpRmKM9CwVVuHf3T12WnRgDaN/On9fEW8XW3NGKwQJYPJSfjAgQPMnz+fRYsWoVar6dmzJ9988w3Vq1c31OncuTONGjV6ZFsjRowgLCyMhg0b0rhxY6ZNm0Z6ejq9e/cGoGfPnpQrV47w8HAAdu/eTUJCAvXq1SMhIYGJEyei0+kYNWqUqV9DiOLv2hlwvecq0ZHlcOIvAFJLubEuy5+12QHs0NXCwcGR3s9X5MPGPjjZyuphQjwtJifhRo0a0bZtW2bNmkVoaGiey/35+vry+uuvP7Ktbt26cfnyZcaPH09SUhL16tVj3bp1hsFa8fHxRvd7MzIyGDt2LGfOnMHe3p4OHTrw66+/4uzsbOrXEKL40ubA7KZw+TgM3g9uVQCI9+nCicuuzEqqSnRGRRTU+JWxZ3LzSnSq54WVpQy2EuJpM/k54XPnzuHj4/Ok4nni5DlhUaxkpMCpf+DScWj10d3yn1+GcztQXpnLVk1T5m49w9aTVwybgyqVpn/zSrSo6o5a/eCxG0II0z3R54QvXbpEUlISgYGBRuW7d+/GwsKChg0bmtqkEMIUN+Ihdh3ErtEPsNJl68sb9QUH/aDGrPbfsC4um+//ucSJJP1UsBZqFR3qeNKvmS91yzubKXghxL1MTsKDBg1i1KhRuZJwQkICX3zxBbt37y604IQQgE4HFw/Cv/+NZk6OMd5eugpUaw+KQkpGNov3xPPTtrMkpWQAYKuxoFsjb/o87yuDrYQoYkxOwseOHaN+/fq5ygMCAuQZXCEKS9YtiNusT7r/roO0ex7lU6mhQhBUbadPvm5+XLxxmwXbzrJw92HSMnMAcHewoleTirwZKIOthCiqTE7CVlZWJCcn53o2NzExEUtLWRlRiMemKDCjkeH5XQA0DlClNVTrAH5t9fM1A8cupjB3STT/O3SRHJ1+eIdfGXv6yWArIZ4JJmfNF198kTFjxvDnn3/i5OQEwI0bN/jwww9p27ZtoQcoRLGWkQJ7foAL+6H7IlCp9K+KTeHcdv2ZbrX24NPUsCygoihsO3mZOVuMB1s9V8mV/2teWQZbCfEMMTkJf/XVVzRv3hwfHx/D8oHR0dF4eHjw66+/FnqAQhQrOVn6M9w7z+9aaGDrVMi+BUmHwdNfX97xa9DY6RPyf7K1Ov536CJztpzhRJJ+IRK1CjrW9ZLBVkI8o0xOwuXKlePw4cP8/vvvHDp0CBsbG3r37k337t3zfGZYiBLv1jU4GakfWHUqChy9YNB/AxhLWUPzkWBbGpy87+5jZW94m5qRzaI98czffva/dXxlsJUQxUWBbuLa2dnRv3//wo5FiOLjyqm7o5njd4GivbvtlrU+Mf93X5dm7+XZROLN28zffpZFu+NJvW+wVY/ACjjbap70txBCPGEFHkl17Ngx4uPjycrKMip/+eWXHzsoIZ452hy4sOfuoghXTxpvL1Prv/u7HcArAB6y8texiynM23qG1fcMtqpSxp7+zSrRKUAGWwlRnJichM+cOUPnzp05cuQIKpWKOxNu3VkxSavVPmx3IYqXzFSIGAkn/4bb1+6Wq0vpB1dVa69/lMjl4bPMKYrCtlNXcg22CvR15f9aVKJl1TIy2EqIYsjkJDxs2DB8fX2JiorC19eXPXv2cPXqVd577z2++uqrJxGjEEXHjfNw9RRUfkH/WWMPZ7fqE7C1M1QN1ifeyq3B2vGRzWVrdfx1+CJztsRxPFG/zKZaxX8zW1XCX5YRFKJYMzkJ79y5kw0bNuDm5oZarUatVtO0aVPCw8MZOnQoBw8efBJxCmF+F/bDvFZg4wrvnwK1hX70crvP9QOrvAPBIn//pVIzslm85zw/bY8zDLayKaUfbNW3qQy2EqKkMDkJa7VaHBwcAHBzc+PixYtUq1YNHx8fYmNjCz1AIZ667NtwZrN+YJWDJ7T8QF/u6Q+2buDmB+mXDfM0UzP/4yASb95mwfazLLxnsJWbvRW9n5fBVkKURCYn4dq1a3Po0CF8fX0JDAxkypQpaDQa5syZk2sWLSGeGWmX9NNDxq6F0xsh57a+3MkbWozWn/FaWMLwI6Ax/Sz1eGIKc7eeYXX03cFWld3t6N+8Ep3qlcO6lAy2EqIkMjkJjx07lvT0dAAmT57MSy+9RLNmzShdujRLliwp9ACFeCIUBS4duzuaOWE/cM+qno7l785WpSh3J80wIQErisL2U1eZs/UMW/69bCgP9HWlf/NKvFBNBlsJUdKZnISDg4MN76tUqcKJEye4du0aLi4uhhHSQhRJOVn6qSD//W8ZwBvxxtu9AvSPEFVrDx61jWarMkW2VkfE4UTmbDnDsXsGW7Wv40l/GWwlhLiHSUk4OzsbGxsboqOjqV27tqHc1dW10AMTolDodHefyb15Hn4NvbvN0hp8W9x9jMjR87EOlZqRzZK95/lpWxwXZbCVECIfTErCpUqVokKFCvIssCj6zu+BqMlg5wavLdCXla6sXwjBtaL+jLdSS/38zI8p6WYG87fHyWArIYTJTL4c/dFHH/Hhhx/y66+/yhmwKBp0WriwV//Mbtn/rtBYlNI/v1vKTn8Z+r8ViOgdUWiHPZGUwpwtMthKCFFwJifhGTNmcOrUKby8vPDx8cHOzvhM4sCBA4UWnBAPlJkKpzdA7Do4uR5uXQX/N6DzLP12z3rQcap+DV7LwjsTlcFWQojCZHISDg0NfQJhCJFPx/6EA79A3BbQ3jNvubUTWDnc/axSQaO+hXbYhw226tesEvVksJUQogBMTsITJkx4EnEI8XDZt2HN+3DwnjWrXXzvjmau8Jz+EnQhe9hgqz7P+1KhtAy2EkIUXIFXURLiqblyCpaFQXIMoIImQyDgTXCrWuDHiB4l6WYG83f8N9gq4+5gq15NfOgR6IOLnQy2EkI8PpOTsFqtfujzwDJyWhSqmBWweihkpYKdO3SZpx/V/IScSEph7pY4Vh9KIFt7d7BVv2aVCA2QwVZCiMJlchJeuXKl0efs7GwOHjzIzz//zKRJkwotMCHYNRvWjda/93keuvz42M/y5kVRFHacvsqcLWfYfM9gq8a+rvRvVolW1WWwlRDiyTA5CXfq1ClX2auvvkqtWrVYsmQJffsW3mAYUcLVeAm2TIH6PeGFsfleoSi/srU61hzRD7Y6evGewVa1PXm7mS8BFVwK9XhCCHG/Qvut9txzz9G/f//Cak6UVJdjwb2a/r1TeRi8D2wL93n0tMwcFu+JZ/72syTc0C/UYFPKgq4Ny9OnqS8+pR9/Ag8hhMiPQknCt2/f5rvvvqNcuXKF0ZwoiRQFIsfDjunw+kKo3kFfXogJODklg5+23z/YSkNYUEXefE4GWwkhnj6Tk/D9CzUoikJqaiq2trb89ttvhRqcKEFUKtDlAApcPHg3CReC2KRU5m49w5/RdwdbVfpvsFVnGWwlhDAjk5PwN998Y5SE1Wo17u7uBAYG4uIi99CEibQ5d+/1tpkEfm2hcqvHblZRFHaevsoP9w+2qqif2UoGWwkhigKTk3CvXr2eQBiixNFpYVM4nNsJPf/UJ2JLzWMn4DuDreZuPUNMwt3BVu1ql6Vfs0oy2EoIUaSYnITnz5+Pvb09r732mlH5smXLuHXrFmFhYYUWnCimUpPhj776BRYA/l0LNUIeq8m8BltZl1LTraG3DLYSQhRZJifh8PBwfvjhh1zlZcqUoX///pKExcPFbYHlfSH9kn6Fo5BvHysBJ6dkMH/7WX7ffU4GWwkhnjkmJ+H4+Hh8fX1zlfv4+BAfH18oQYliSKeDbV/Dxs9A0YF7Dej6C7hXLVBzMthKCFEcmJyEy5Qpw+HDh6lYsaJR+aFDhyhdunRhxSWKk/SrsKIfnI7Sf67XAzp8BRrTFz/Yf+460zecZFOs8WCrfs0r0VoGWwkhnjEmJ+Hu3bszdOhQHBwcaN68OQCbN29m2LBhvP7664UeoHjGxe+G5b0hJQEsbaDjV/rFF0yk0yl8v+kUUyP/RafIYCshRPFgchL++OOPOXv2LK1bt8bSUr+7TqejZ8+efPbZZ4UeoHhGKQrsnAH/TNQ//1vaD7r+DB61TG7qWnoWw5dEs+W/R41C63nxbtuqMthKCPHMMzkJazQalixZwieffEJ0dDQ2NjbUqVMHHx+fJxGfeBbdvgGr3oHYCP3n2l30A7CsHExuat/ZawxeeJCklAysS6mZ3Kk2XRt6F268QghhJgWettLPzw8/P7/CjEUUF2oLuBILFhpo9zk07GPyur+KojBvaxyfrzuBVqdQyd2O73vUp3pZxycUtBBCPH0mJ+EuXbrQuHFjRo8ebVQ+ZcoU9u7dy7JlywotOPEMUfQjlFGp9Ge8XX8FbRZ41TO5qZu3shm5/BCRx5IBeNnfi89eqYO9VeGuoiSEEOamNnWHLVu20KFD7nl927dvz5YtWwolKPGMyUjRD77aNetumUfNAiXgwxdu0HH6ViKPJaOxUPNJaG2+fb2eJGAhRLFk8m+2tLQ0NJrcEyCUKlWKlJSUQglKPGOO/w+OroTYdVC3K9i5mdyEoij8uuscn/x1nCytjgqutnzfoz61yzk9gYCFEKJoMPlMuE6dOixZsiRX+eLFi6lZs2ahBCWeMfXegMCBELa6QAk4NSObwYsOMv7Po2RpdQTX8uB/Q5pKAhZCFHsmnwmPGzeOV155hdOnT9OqlX6y/aioKBYuXMjy5csLPUBRBGWlw6bPoflIsHbS3wdu/3mBmjp2MYVBCw8QdyUdS7WKMR1q0Of5ikYrdQkhRHFlchIOCQlh1apVfPbZZyxfvhwbGxv8/f3ZsGEDrq6FtwC7KKIux8LSMLh8HG7E65/9LQBFUVi67zzj/zxKZo4OLydrZvSoT32ZeEMIUYKYfDkaoGPHjmzfvp309HTOnDlD165dGTlyJP7+/ia3NXPmTCpWrIi1tTWBgYHs2bPnofWnTZtGtWrVsLGxwdvbm3fffZeMjIyCfA1hqsNLYc4L+gRs7wGN+xWomVtZOby37BCj/zhCZo6OF6q5EzG0mSRgIUSJU+Ahp1u2bOHHH3/kjz/+wMvLi1deeYWZM2ea1MaSJUsYMWIEs2fPJjAwkGnTphEcHExsbCxlypTJVX/hwoV88MEH/PTTTzRp0oR///2XXr16oVKpmDp1akG/iniU7AxYNxr2L9B/9m0BXeaBfe5/o0c5dSmVgb8d4OSlNNQqGBlcjQHNK8ucz0KIEsmkJJyUlMSCBQv48ccfSUlJoWvXrmRmZrJq1aoCDcqaOnUq/fr1o3fv3gDMnj2biIgIfvrpJz744INc9Xfs2MHzzz/PG2+8AUDFihXp3r07u3fvNvnYIp+unoZlYZB0BFBBi1HQYrR+Qg4TrTqYwIcrj3ArS0sZByu+6x7Ac5Vk0Q8hRMmV78vRISEhVKtWjcOHDzNt2jQuXrzI9OnTC3zgrKws9u/fT5s2be4Go1bTpk0bdu7cmec+TZo0Yf/+/YZL1mfOnGHNmjV5PrcsCsGxP2FOS30Cti0Nb/4BL3xocgLOyNYyZsURhi+J5laWluerlCZiaDNJwEKIEi/fZ8Jr165l6NChDBw4sFCmq7xy5QparRYPDw+jcg8PD06cOJHnPm+88QZXrlyhadOmKIpCTk4OAwYM4MMPP3zgcTIzM8nMzDR8Tk1NfezYi72cLIgcD7v/m3yjQhC8+hM4epnc1Nkr6bzz+wGOJaagUsHQVn4Mbe2HhVx+FkKI/J8Jb9u2jdTUVBo0aEBgYCAzZszgypUrTzK2XDZt2sRnn33G999/z4EDB1ixYgURERF8/PHHD9wnPDwcJycnw0ueZX6EG/Ewv93dBPz8MAj7X4ES8Nojibw0fRvHElMobafhlz6NebdtVUnAQgjxH5Wi3Jn0N3/S09NZsmQJP/30E3v27EGr1TJ16lT69OmDg0P+V8nJysrC1taW5cuXExoaaigPCwvjxo0b/Pnnn7n2adasGc899xxffvmloey3336jf//+pKWloVbn/pvi/jPhhIQEatasyfnz5ylfvny+4y0xlrwFx1eDtTN0ng3V2pvcRFaOjvC1x5m//SwAjSq6ML17fco6WRdurEIIUQRduHABb2/vfOUZkx9RsrOzo0+fPmzbto0jR47w3nvv8fnnn1OmTBlefvnlfLej0Who0KABUVFRhjKdTkdUVBRBQUF57nPr1q1cidbCQn9/8kF/S1hZWeHo6Gh4mfKHQonU4Suo1gH+b0uBEvCF67d47YedhgQ8oEVlFvV7ThKwEELkoUDPCd9RrVo1pkyZwoULF1i0aJHJ+48YMYK5c+fy888/c/z4cQYOHEh6erphtHTPnj0ZM2aMoX5ISAizZs1i8eLFxMXFERkZybhx4wgJCTEkY2GilETY/cPdzw4e0H0RuJi+PnTU8WQ6freNQ+dv4GRTih/DGvJB++pYWjzWj5kQQhRbhbI0jYWFBaGhoUaXlfOjW7duXL58mfHjx5OUlES9evVYt26dYbBWfHy80Znv2LFjUalUjB07loSEBNzd3QkJCeHTTz8tjK9R8mTchB+aQ/ol/ejnOq8WqJkcrY4v/47lh81nAPD3dmbmGwGUd7EtzGiFEKLYMfme8LPOlGv1JULUx/Dvev30k6Urm7x70s0Mhi46yJ6z1wDo/XxFxrSvgcZSzn6FECWTKXlGFmktadIuQ04GOHvrP7cco1+IoZSNyU1tPXmZ4YujuZqehb2VJVNerUuHOp6FHLAQQhRfkoRLkrPbYXkfcCgLff8GSyuwsNS/TKDVKXwbdZLpG06iKFDT05Hve9SnopvdEwpcCCGKJ0nCJYFOBzu+1V96VrT65QfTL4OT6ZfjL6dmMnzJQbafugpA98YVmBBSE+tSMjBOCCFMJUm4uLt1DVb+H5z8W/+57uvw0lTQmH7WuvvMVYYsOsil1ExsNRZ81rkOoQHlCjlgIYQoOSQJF2fn98KyXpByASytof0UqN8TVKbNWKXTKczecpqv1seiU8CvjD2z3qxPlTLyzLUQQjwOScLFkaLArlkQOQ50OeBaCbr+AmXrmNzU9fQsRiyNZmPsZQBeCSjHJ51rY6uRHx0hhHhc8pu0uLl9A/4cBCf+0n+uGQovTwdrR5ObOhB/ncG/H+DizQysLNVM7lSLrg29UZl4Ji2EECJvkoSLk4vR+rV/r58FdSkI/gwa9zP58rOiKPy0/Szha46To1PwdbNj5hv1qelleiIXQgjxYJKEi4u4rfBbF9BmglMF6LoAyjUwuZmbt7MZtfwQ648mA9Cxjiefd6mDg3WpQg5YCCGEJOHionxDcPMDJ28I/R5sXU1uIibhJu/8foD4a7coZaFi3Es1ees5H7n8LIQQT4gk4WfZtTPgXBHUav2MV2H/AxuXAl1+/n13PJP/d4wsrY7yLjbMfKM+/t7OTyRsIYQQejLB77Pq0BL4vgls/fpuma2ryQk4LTOHYYujGbsqhiytjjY1PIgY0kwSsBBCPAVyJvys0uVAzm04v1s/I5ba9L+nTiSl8M7vBzhzOR0LtYoP2lXn7Wa+cvlZCCGeEknCzxKdFtT/TQ8Z0EN/6blqcIES8LJ95xn3ZwwZ2TrKOloz440AGlY0/T6yEEKIgpPL0c+KmD/g+yBIv3q3rHqHu0k5n25naXl/2SHeX36YjGwdzau6EzG0qSRgIYQwAzkTLupyMmH9h7B3nv7zrpnQenyBmjp9OY1Bvx/gRFIqahWMaFuVd1pWQa2Wy89CCGEOkoSLsmtx+rmfE6P1n5uN1K//WwCrD11kzB+HSc/S4mZvxXfd69GksluhhSqEEMJ0koSLquN/wap3IPMm2LjCK3PAr63JzWRka/kk4hi/7YoH4LlKrnzXPYAyDtaFHbEQQggTSRIuarTZ8M9E2DlD/7l8Y3htfoHW/o2/eot3Fu4nJiEFgCGtqjCstR+WFjIUQAghigJJwkXJzQuwrDdc2KP/HDQY2kwEC9OnjFx/NImRyw6RmpGDi20pvulWj5bVyhRuvEIIIR6LJOGi4mQkrOgPt6+BlZN+6skaL5ncTLZWxxdrTzBvWxwADXxcmN49AC9nm8KOWAghxGOSJGxuOi1s/PTuzFee9eC1BeDqa3JTCTduM3jhAQ7G3wCgXzNfRrWrTim5/CyEEEWSJGGzU0HyUf3bRm/rlx+0tDK5lY2xl3h3STQ3bmXjaG3JV6/582KtsoUcqxBCiMIkSdhcFEU/z7NaDaGz4OxWqNnJ5GZytDq++edfZm48DUDd8k7MfKM+3q62hR2xEEKIQiZJ+GnT6fSXnq+fhU4z9InY1rVACfhSSgZDFh1kd9w1AHoG+fBRxxpYWZo2i5YQQgjzkCT8tCUfgU2fgaKDet2hYtMCNbPj1BWGLj7IlbQs7DQWfN6lLiH+XoUcrBBCiCdJkvDT5ukPbT/WL75QgASs0ynM2HiKb/75F0WB6mUd+L5HfSq52z+BYIUQQjxJkoSfNEWBnTPB70Vwr6ovazK4QE1dTctk+JJotp68AkC3ht5M6lQL61Jy+VkIIZ5FkoSfpNvXYeVA+HctHPwN+m+CUgWbLnLv2WsMWXiQpJQMrEup+SS0Dq82MH0WLSGEEEWHJOEnJWG/fvGFG/FgoYHA/gV69EinU5i79QxT1sei1SlUdrfj+x4NqFbWofBjFkII8VRJEi5sigJ75uqXH9Rlg0tFeO1n8KpnclM3bmUxctkh/jl+CYBO9bz4rHMd7Kzkn00IIYoD+W1emDJSYPUQOLZK/7lGCHSaCdZOJjcVff4Gg34/QMKN22gs1UwMqUX3xt6oVLL2rxBCFBeShAtL0hFYGgbXToPaEl78BAIH6J8DNoGiKPy84yyfrjlOtlbBp7QtM9+oT+1ypidyIYQQRZsk4celKHDgF1g7CnIywLG8fu5n70YmN5WSkc0HfxxmzZEkANrXLssXr9bF0dr0VZSEEEIUfZKEH0dWOvw1Ag4v1n/2exE6/6CfActERy/eZNDvBzh79RalLFR82KEGvZpUlMvPQghRjEkSfhy7Z+sTsMoCWo+DJsP0c0GbQFEUFu89z4TVR8nK0VHO2YYZbwQQUMHlCQUthBCiqJAk/DiChkDCAXjuHaj4vMm7p2fmMHZVDCsPJgDQqnoZpnb1x9lWU9iRCiGEKIIkCT8OSw28/nuBdj2ZnMrA3w9w6lIaFmoV7wdXo3+zSqjVcvlZCCFKCknCZrDiwAU+WhnD7WwtHo5WTO9en8a+pt9HFkII8WyTJPwUZWRrmfS/oyzacx6AplXcmPZ6PdzsTZ9JSwghxLNPkvBTEnclnXd+P8DxxBRUKhjW2o8hrfywkMvPQghRYkkSfgoiDicy+o/DpGXmUNpOw7evB9DUz83cYQkhhDAzScJPUGaOls8ijvPzznMANPZ1ZXr3ADwcC7aSkhBCiOJFkvATcv7aLQYvPMChCzcBGNiyMu+1rYqlhWnPEQshhCi+JAk/AZHHknlvaTQpGTk42ZTim27+tKruYe6whBBCFDGShAtRtlbHV+tj+WHLGQDqeTsz440AyrvYmjkyIYQQRVGRuDY6c+ZMKlasiLW1NYGBgezZs+eBdVu2bIlKpcr16tix41OMOLfEm7fpPmeXIQH3ed6Xpf8XJAlYCCHEA5n9THjJkiWMGDGC2bNnExgYyLRp0wgODiY2NpYyZcrkqr9ixQqysrIMn69evYq/vz+vvfba0wzbyJZ/LzN8STTX0rNwsLLky9fq0q62p9niEUII8Www+5nw1KlT6devH71796ZmzZrMnj0bW1tbfvrppzzru7q6UrZsWcMrMjISW1tbsyRhrU5h6t+xhM3fw7X0LGp5OfLX0KaSgIUQQuSLWc+Es7Ky2L9/P2PGjDGUqdVq2rRpw86dO/PVxo8//sjrr7+OnZ1dntszMzPJzMw0fE5NTX28oP9zKTWDYYui2XnmKgA9Aisw7qWaWJeyKJT2hRBCFH9mPRO+cuUKWq0WDw/jkcMeHh4kJSU9cv89e/YQExPD22+//cA64eHhODk5GV41a9Z87LgBzl+7zd6z17DVWPDt6/X4tHMdScBCCCFMYvbL0Y/jxx9/pE6dOjRu3PiBdcaMGcPNmzcNr2PHjhXKsRv4uDDl1bqsHtyUTvXKFUqbQgghShazXo52c3PDwsKC5ORko/Lk5GTKli370H3T09NZvHgxkydPfmg9KysrrKzuLpCQkpJS8IDv80r98oXWlhBCiJLHrGfCGo2GBg0aEBUVZSjT6XRERUURFBT00H2XLVtGZmYmb7755pMOUwghhHgizP6I0ogRIwgLC6Nhw4Y0btyYadOmkZ6eTu/evQHo2bMn5cqVIzw83Gi/H3/8kdDQUEqXLm2OsIUQQojHZvYk3K1bNy5fvsz48eNJSkqiXr16rFu3zjBYKz4+HrXa+IQ9NjaWbdu28ffff5sjZCGEEKJQqBRFUcwdxNN04cIFvL29OX/+POXLyz1dIYQQhcuUPPNMj44WQgghnmVmvxz9tOl0OgASExPNHIkQQoji6E5+uZNvHqbEJeE7j0M97NliIYQQ4nElJydToUKFh9YpcfeEc3JyOHjwIB4eHrkGfJkqNTWVmjVrcuzYMRwcHAopwuJH+in/pK/yT/oqf6Sf8q+w+kqn05GcnExAQACWlg8/1y1xSbgwpaSk4OTkxM2bN3F0dDR3OEWW9FP+SV/ln/RV/kg/5Z85+koGZgkhhBBmIklYCCGEMBNJwo/BysqKCRMmGM1NLXKTfso/6av8k77KH+mn/DNHX8k9YSGEEMJM5ExYCCGEMBNJwkIIIYSZSBIWQgghzESScAHNnDmTihUrYm1tTWBgIHv27DF3SEXSli1bCAkJwcvLC5VKxapVq8wdUpEUHh5Oo0aNcHBwoEyZMoSGhhIbG2vusIqcWbNmUbduXRwdHXF0dCQoKIi1a9eaO6wi7/PPP0elUjF8+HBzh1LkTJw4EZVKZfSqXr36Uzu+JOECWLJkCSNGjGDChAkcOHAAf39/goODuXTpkrlDK3LS09Px9/dn5syZ5g6lSNu8eTODBg1i165dREZGkp2dzYsvvkh6erq5QytSypcvz+eff87+/fvZt28frVq1olOnThw9etTcoRVZe/fu5YcffqBu3brmDqXIqlWrFomJiYbXtm3bnt7BFWGyxo0bK4MGDTJ81mq1ipeXlxIeHm7GqIo+QFm5cqW5w3gmXLp0SQGUzZs3mzuUIs/FxUWZN2+eucMoklJTUxU/Pz8lMjJSadGihTJs2DBzh1TkTJgwQfH39zfb8eVM2ERZWVns37+fNm3aGMrUajVt2rRh586dZoxMFCc3b94EwNXV1cyRFF1arZbFixeTnp5OUFCQucMpkgYNGkTHjh2Nfl+J3E6ePImXlxeVKlWiR48exMfHP7Vjl7hVlB7XlStX0Gq1eHh4GJV7eHhw4sQJM0UlihOdTsfw4cN5/vnnqV27trnDKXKOHDlCUFAQGRkZ2Nvbs3LlSmrWrGnusIqcxYsXc+DAAfbu3WvuUIq0wMBAFixYQLVq1UhMTGTSpEk0a9aMmJiYp7LghSRhIYqYQYMGERMT83TvSz1DqlWrRnR0NDdv3mT58uWEhYWxefNmScT3OH/+PMOGDSMyMhJra2tzh1OktW/f3vC+bt26BAYG4uPjw9KlS+nbt+8TP74kYRO5ublhYWFhWJf4juTkZMqWLWumqERxMXjwYP766y+2bNlC+fLlzR1OkaTRaKhSpQoADRo0YO/evXz77bf88MMPZo6s6Ni/fz+XLl2ifv36hjKtVsuWLVuYMWMGmZmZWFhYmDHCosvZ2ZmqVaty6tSpp3I8uSdsIo1GQ4MGDYiKijKU6XQ6oqKi5L6UKDBFURg8eDArV65kw4YN+Pr6mjukZ4ZOpyMzM9PcYRQprVu35siRI0RHRxteDRs2pEePHkRHR0sCfoi0tDROnz6Np6fnUzmenAkXwIgRIwgLC6Nhw4Y0btyYadOmkZ6eTu/evc0dWpGTlpZm9BdlXFwc0dHRuLq6UqFCBTNGVrQMGjSIhQsX8ueff+Lg4EBSUhIATk5O2NjYmDm6omPMmDG0b9+eChUqkJqaysKFC9m0aRPr1683d2hFioODQ67xBHZ2dpQuXVrGGdxn5MiRhISE4OPjw8WLF5kwYQIWFhZ07979qRxfknABdOvWjcuXLzN+/HiSkpKoV68e69atyzVYS8C+fft44YUXDJ9HjBgBQFhYGAsWLDBTVEXPrFmzAGjZsqVR+fz58+nVq9fTD6iIunTpEj179iQxMREnJyfq1q3L+vXradu2rblDE8+oCxcu0L17d65evYq7uztNmzZl165duLu7P5XjyypKQgghhJnIPWEhhBDCTCQJCyGEEGYiSVgIIYQwE0nCQgghhJlIEhZCCCHMRJKwEEIIYSaShIUQQggzkSQshBBCmIkkYSFEoVGpVKxatcrcYQjxzJAkLEQx0atXL1QqVa5Xu3btzB2aEOIBZO5oIYqRdu3aMX/+fKMyKysrM0UjhHgUORMWohixsrKibNmyRi8XFxdAf6l41qxZtG/fHhsbGypVqsTy5cuN9j9y5AitWrXCxsaG0qVL079/f9LS0ozq/PTTT9SqVQsrKys8PT0ZPHiw0fYrV67QuXNnbG1t8fPzY/Xq1YZt169fp0ePHri7u2NjY4Ofn1+uPxqEKEkkCQtRgowbN44uXbpw6NAhevToweuvv87x48cBSE9PJzg4GBcXF/bu3cuyZcv4559/jJLsrFmzGDRoEP379+fIkSOsXr2aKlWqGB1j0qRJdO3alcOHD9OhQwd69OjBtWvXDMc/duwYa9eu5fjx48yaNQs3N7en1wFCFDWKEKJYCAsLUywsLBQ7Ozuj16effqooiqIAyoABA4z2CQwMVAYOHKgoiqLMmTNHcXFxUdLS0gzbIyIiFLVarSQlJSmKoiheXl7KRx999MAYAGXs2LGGz2lpaQqgrF27VlEURQkJCVF69+5dOF9YiGJA7gkLUYy88MILhrWJ73B1dTW8DwoKMtoWFBREdHQ0AMePH8ff3x87OzvD9ueffx6dTkdsbCwqlYqLFy/SunXrh8ZQt25dw3s7OzscHR25dOkSAAMHDqRLly4cOHCAF198kdDQUJo0aVKg7ypEcSBJWIhixM7OLtfl4cJiY2OTr3qlSpUy+qxSqdDpdAC0b9+ec+fOsWbNGiIjI2ndujWDBg3iq6++KvR4hXgWyD1hIUqQXbt25fpco0YNAGrUqMGhQ4dIT083bN++fTtqtZpq1arh4OBAxYoViYqKeqwY3N3dCQsL47fffmPatGnMmTPnsdoT4lkmZ8JCFCOZmZkkJSUZlVlaWhoGPy1btoyGDRvStGlTfv/9d/bs2cOPP/4IQI8ePZgwYQJhYWFMnDiRy5cvM2TIEN566y08PDwAmDhxIgMGDKBMmTK0b9+e1NRUtm/fzpAhQ/IV3/jx42nQoAG1atUiMzOTv/76y/BHgBAlkSRhIYqRdevW4enpaVRWrVo1Tpw4AehHLi9evJh33nkHT09PFi1aRM2aNQGwtbVl/fr1DBs2jEaNGmFra0uXLl2YOnWqoa2wsDAyMjL45ptvGDlyJG5ubrz66qv5jk+j0TBmzBjOnj2LjY0NzZo1Y/HixYXwzYV4NqkURVHMHYQQ4slTqVSsXLmS0NBQc4cihPiP3BMWQgghzESSsBBCCGEmck9YiBJC7jwJUfTImbAQQghhJpKEhRBCCDORJCyEEEKYiSRhIYQQwkwkCQshhBBmIklYCCGEMBNJwkIIIYSZSBIWQgghzESSsBBCCGEm/w+mswi2yPdp7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aba699-21bc-42de-a69c-99f370bb0363",
   "metadata": {},
   "source": [
    "- 根据上面的准确率图，我们可以看到模型在第 4 轮和第 5 轮之后实现了相对较高的训练和验证准确度\n",
    "- 但是，我们必须记住，我们之前在训练函数中指定了 `eval_iter=5`，这意味着我们只估计了训练集和验证集的性能\n",
    "- 我们可以计算整个数据集的训练、验证和测试集性能，如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "UHWaJFrjY0zW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHWaJFrjY0zW",
    "outputId": "e111e6e6-b147-4159-eb9d-19d4e809ed34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
   "metadata": {},
   "source": [
    "- 我们可以看到训练集和测试集的性能几乎相同\n",
    "- 然而，基于稍低的测试集性能，我们可以看到模型在很小程度上过度拟合了训练数据，以及用于调整一些超参数（例如学习率）的验证数据\n",
    "- 然而，这是正常的，通过增加模型的 dropout 率 (`drop_rate`) 或优化器设置中的 `weight_decay` 可能会进一步缩小这种差距"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
   "metadata": {},
   "source": [
    "## 6.8 使用大模型作为垃圾邮件分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-4.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
   "metadata": {},
   "source": [
    "- 最后，让我们实际使用经过微调的 GPT 模型\n",
    "- 下面的 `classify_review` 函数实现了与我们之前实现的 `SpamDataset` 类似的数据预处理步骤\n",
    "- 然后，该函数从模型中返回预测的整数类标签，并返回相应的类别名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aHdn6xvL-IW5",
   "metadata": {
    "id": "aHdn6xvL-IW5"
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # 准备模型的输入\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    # 如果序列太长则截断\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # 将序列填充到最长序列\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # 添加批次维度\n",
    "\n",
    "    # 模型推理\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # 最后一个输出 token 的 Logits\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # 返回分类结果\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
   "metadata": {},
   "source": [
    "- 让我们尝试下面的几个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "apU_pf51AWSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apU_pf51AWSV",
    "outputId": "d0fde0a5-e7a3-4dbe-d9c5-0567dbab7e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1g5VTOo_Ajs5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1g5VTOo_Ajs5",
    "outputId": "659b08eb-b6a9-4a8a-9af7-d94c757e93c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
   "metadata": {},
   "source": [
    "- 最后，让我们保存模型，以便以后我们想重用该模型而不必再次训练它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mYnX-gI1CfQY",
   "metadata": {
    "id": "mYnX-gI1CfQY"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
   "metadata": {},
   "source": [
    "- 然后，在新会话中，我们可以按如下方式加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
   "metadata": {
    "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
   },
   "source": [
    "## 总结和要点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
   "metadata": {},
   "source": [
    "- 有兴趣的读者可以在附录 E 中找到有关低秩适应（LoRA）的参数高效训练的介绍"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
